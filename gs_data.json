{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "lp5ujPsAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Sizhe Chen", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=lp5ujPsAAAAJ&citpid=5", "affiliation": "UC Berkeley, Meta FAIR", "organization": 11816294095661060495, "interests": ["AI security", "adversarial machine learning"], "email_domain": "@berkeley.edu", "homepage": "https://sizhe-chen.github.io/", "citedby": 1031, "publications": {"lp5ujPsAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "StruQ: Defending against prompt injection with structured queries", "pub_year": "2025"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:8k81kl-MbHgC", "num_citations": 195, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=217240380954211219,1232224593734725072,4358359962429508854", "cites_id": ["217240380954211219", "1232224593734725072", "4358359962429508854"]}, "lp5ujPsAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Universal adversarial attack on attention and the resulting dataset damagenet", "pub_year": "2022"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:eQOLeE2rZwMC", "num_citations": 170, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16244846688496677275,14178099012157782580", "cites_id": ["16244846688496677275", "14178099012157782580"]}, "lp5ujPsAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Jatmo: Prompt injection defense by task-specific finetuning", "pub_year": "2024"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:Zph67rFs4hoC", "num_citations": 138, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1782380435011589188,362130644304834364", "cites_id": ["1782380435011589188", "362130644304834364"]}, "lp5ujPsAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subspace adversarial training", "pub_year": "2022"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:qjMakFHDy7sC", "num_citations": 105, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9851312696966203784", "cites_id": ["9851312696966203784"]}, "lp5ujPsAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SecAlign: Defending Against Prompt Injection with Preference Optimization", "pub_year": "2025"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:KlAtU1dfN6UC", "num_citations": 102, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9982833651907086200,14814994650380797882,16377153953321426125", "cites_id": ["9982833651907086200", "14814994650380797882", "16377153953321426125"]}, "lp5ujPsAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Can LLMs Follow Simple Rules?", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:0EnyYjriUFMC", "num_citations": 67, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6994227226743227264,1101022057548070460,1662740182230572343", "cites_id": ["6994227226743227264", "1101022057548070460", "1662740182230572343"]}, "lp5ujPsAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "One-pixel shortcut: on the learning preference of deep neural networks", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:YsMSGLbcyi4C", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15086814679259659341", "cites_id": ["15086814679259659341"]}, "lp5ujPsAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks", "pub_year": "2022"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:u-x6o8ySG0sC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1904818914099445692", "cites_id": ["1904818914099445692"]}, "lp5ujPsAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:_FxGoFyzp5QC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3909749085867735425", "cites_id": ["3909749085867735425"]}, "lp5ujPsAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Relevance attack on detectors", "pub_year": "2022"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:2osOgNQ5qMEC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9673919338872868997,4264544752968265810", "cites_id": ["9673919338872868997", "4264544752968265810"]}, "lp5ujPsAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "pub_year": "2025"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:QIV2ME_5wuYC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14694239694720190383", "cites_id": ["14694239694720190383"]}, "lp5ujPsAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Colonoscopic image synthesis for polyp detector enhancement via gan and adversarial training", "pub_year": "2021"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:9yKSN-GCB0IC", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6326423841350598649", "cites_id": ["6326423841350598649"]}, "lp5ujPsAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Defending against prompt injection with a few defensivetokens", "pub_year": "2025"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:dhFuZR0502QC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=894285751003496684", "cites_id": ["894285751003496684"]}, "lp5ujPsAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Investigating Catastrophic Overfitting in Fast Adversarial Training: A Self-fitting Perspective", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:WF5omc3nYNoC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12635110879056460398", "cites_id": ["12635110879056460398"]}, "lp5ujPsAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Type I attack for generative models", "pub_year": "2020"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:Tyk-4Ss8FVUC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11076496357489066304", "cites_id": ["11076496357489066304"]}, "lp5ujPsAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Double backpropagation for training autoencoders against adversarial attack", "pub_year": "2020"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:Y0pCki6q_DkC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13072442005242353169", "cites_id": ["13072442005242353169"]}, "lp5ujPsAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Defending Against Prompt Injection with DataFilter", "pub_year": "2026"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:7PzlFSSx8tAC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4146447851391822421", "cites_id": ["4146447851391822421"]}, "lp5ujPsAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Measuring the Transferability of ℓ∞ Attacks by the ℓ2 Norm", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:ufrVoPGSRksC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10479482598278742056,5451583749068738619,7842202977848902048", "cites_id": ["10479482598278742056", "5451583749068738619", "7842202977848902048"]}, "lp5ujPsAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dominant patterns: Critical features hidden in deep neural networks", "pub_year": "2021"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:aqlVkmm33-oC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1530167288267198716", "cites_id": ["1530167288267198716"]}, "lp5ujPsAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unifying gradients to improve real-world robustness for deep networks", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:d1gkVwhDpl0C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11633127993814941486", "cites_id": ["11633127993814941486"]}, "lp5ujPsAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Query attack by multi-identity surrogates", "pub_year": "2023"}, "filled": false, "author_pub_id": "lp5ujPsAAAAJ:UeHWp8X0CEIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9908720743606179795,10096499352833856913", "cites_id": ["9908720743606179795", "10096499352833856913"]}}, "citedby5y": 1024, "hindex": 13, "hindex5y": 13, "i10index": 16, "i10index5y": 16, "cites_per_year": {"2020": 6, "2021": 25, "2022": 65, "2023": 110, "2024": 263, "2025": 516, "2026": 43}, "updated": "2026-01-30 08:40:29.183758"}